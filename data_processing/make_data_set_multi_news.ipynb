{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 기존 데이터셋 정제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../data/origin/multi_news_train.tgt\"\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    target = f.readlines()\n",
    "file_path = \"../data/origin/multi_news_train.src.cleaned\"\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    source = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Karma's a brick. An attempted burglary in Suitland, Maryland, went all wrong when the suspect's brick ricocheted off bulletproof glass and into his face. Prince George's County police released surveillance video from the scene. (Published Monday, Oct. 1, 2018) NEWLINE_CHAR NEWLINE_CHAR An attempted burglary in Suitland, Maryland, went all wrong when the suspect's brick ricocheted off bulletproof glass and smashed into his head. NEWLINE_CHAR NEWLINE_CHAR Police are calling him the \"Bad Luck Bandit.\" NEWLINE_CHAR NEWLINE_CHAR The suspect shattered the front glass to get inside a waiting area of a takeout restaurant, police said. Surveillance video shows him then trying to break through a window to a back room. NEWLINE_CHAR NEWLINE_CHAR The suspect lobbed the brick once, then twice, but the bulletproof glass resisted. He wound up his pitch for a third attempt and flung the brick to the window. It bounced back. NEWLINE_CHAR NEWLINE_CHAR The suspect flinched, but it was too late. NEWLINE_CHAR NEWLINE_CHAR The brick smacked him in the head, sending him to his hands and knees. NEWLINE_CHAR NEWLINE_CHAR He tried to pick himself — and the brick — up again, before realizing the extent of his pain. Video shows the suspect rolled back, lay down on the restaurant floor and stayed there. NEWLINE_CHAR NEWLINE_CHAR Police say he was on the ground for several minutes before giving up and leaving. NEWLINE_CHAR NEWLINE_CHAR Prince George's County police are looking for the suspect. He was in the area of the restaurant in the 4000 block of Suitland Road in Suitland, Maryland, in the early hours of Sept. 20, police say. ||||| Rating is available when the video has been rented. NEWLINE_CHAR NEWLINE_CHAR This feature is not available right now. Please try again later. ||||| Detectives in Prince George's County are searching for a burglar who had some bad luck while trying to rob a carryout in Suitland last month. NEWLINE_CHAR NEWLINE_CHAR According to police, the bandit threw a brick or a large rock at the restaurant located in the 4000 block of Suitland Road on September 20, and successfully shattered the front glass window. NEWLINE_CHAR NEWLINE_CHAR But when he tried to use that same brick or rock in an attempt to break the bulletproof glass that protected the front counter three times, police say the brick or rock flew back at him and appeared to hit him in the head on the third try. NEWLINE_CHAR NEWLINE_CHAR After being hit in the head, police say the suspect fell to the ground and laid there for a few minutes before eventually getting up and leaving the business. NEWLINE_CHAR NEWLINE_CHAR If you have any information on this incident or know someone with a suspicious head injury, call PGPD at 301-390-2160 or 1-866-411-TIPS. NEWLINE_CHAR NEWLINE_CHAR NEWLINE_CHAR NEWLINE_CHAR NEWLINE_CHAR NEWLINE_CHAR NEWLINE_CHAR NEWLINE_CHAR NEWLINE_CHAR NEWLINE_CHAR\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(source[2126])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "def split_into_sentences(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    return sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_result = []\n",
    "for source_line, target_line in zip(source, target):\n",
    "    result = {}\n",
    "    all_sent = \"\"\n",
    "    sentences = re.split(r'NEWLINE_CHAR|\\|\\|\\|\\|\\|', source_line)\n",
    "    for sentence in sentences:\n",
    "        if sentence == \" \":\n",
    "            continue\n",
    "        all_sent = all_sent + \"\\n\" + sentence.strip()\n",
    "    all_sent = all_sent.strip()\n",
    "    \n",
    "    result[\"document\"] = all_sent\n",
    "    result[\"summary\"] = target_line.replace(\"– \", \"\")\n",
    "    all_result.append(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Da Vinci Code has sold so many copies—that would be at least 80 million—that it's bound to turn up in book donation piles. But at one charity shop in the UK, it's been donated so heavily that the shop has posted a sign propped up on a tower of Da Vinci Code copies that reads: \"You could give us another Da Vinci Code... but we would rather have your vinyl!\" The manager of the Oxfam shop in Swansea tells the Telegraph that people are laughing and taking pictures of the sizable display: \"I would say that we get one copy of the book every day.\" He says people buy them \"occasionally,\" but with vinyl sales up 25% in the past year, they'd rather take records. Dan Brown's book isn't the only one that shops like Oxfam struggle to re-sell. Last year, Oxfam was hit with a large and steady supply of Fifty Shades of Grey, and it similarly begged donors: \"Please—no more.\" But Brown has a particular kind of staying power. The Da Vinci Code was published in 2003, and within six years Brown had booted John Grisham from the No. 1 slot on the list of writers whose books were most often donated to Oxfam's 700 shops, reported the Guardian at the time. The Independent in 2012 reported Brown's best-seller was the most-donated book for the fourth year running. (See why Dan Brown took heat from the Philippines.)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(all_result[0][\"summary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "file_path = \"../data/multi-news_dev.json\"\n",
    "with open(file_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(all_result, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train 데이터 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def create_example(all_data):\n",
    "    all_result = []\n",
    "    for data in tqdm(all_data):\n",
    "        # data_id = data[\"id\"]\n",
    "        summary = data[\"summary\"]\n",
    "        context = data[\"document\"].split(\"\\n\")\n",
    "        total_sentence_number = 1\n",
    "        sentences = \"\"\n",
    "        for sent in context:\n",
    "            sentence = \"[{}] {}\".format(total_sentence_number, sent) + \"\\n\"\n",
    "            sentences = sentences + sentence\n",
    "            total_sentence_number += 1\n",
    "\n",
    "        \n",
    "        sentence = sentence.rstrip(\"\\n\")\n",
    "        instruction = \"<|mrc|>False\\n<|summary|>True\"\n",
    "        prompt = (\n",
    "            \"**Document**\\n{}\".format(sentences)\n",
    "        )\n",
    "\n",
    "        response = \"**Answer**\\n**Summary**\\n{}\".format(summary)\n",
    "        # response = \"**Answer**: {}\\n**Supporting Sentences**: {}\".format(answer, supporting_sentence)\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": instruction},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "            # {\"role\": \"assistant\", \"content\": response},\n",
    "        ]\n",
    "        result = {}\n",
    "        result[\"text\"] = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": instruction},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "            {\"role\": \"assistant\", \"content\": response},\n",
    "        ]\n",
    "        result[\"all_text\"] = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "        result[\"label\"] = response\n",
    "        all_result.append(result)\n",
    "        supporting_sentence = \"\"\n",
    "        # print(model_answer)\n",
    "        # if len(all_result) ==1000:\n",
    "        #     break\n",
    "    return all_result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rbqlsquf2/workspace/XAI_rationale-inference-LLM/.venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.36s/it]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "model_path = \"Qwen/Qwen2.5-3B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    ")\n",
    "tokenizer.padding_side = 'left'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_special_tokens = {\"additional_special_tokens\": [\"<|mrc|>\", \"<|summary|>\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.add_special_tokens(new_special_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(151667, 2048)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5622/5622 [00:00<00:00, 10296.73it/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "file_path = \"../data/multi-news_dev.json\"\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "input_data = create_example(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/qwen_multi_news_train_chat_tmp.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(input_data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2270/5622 [00:10<00:14, 225.58it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (176418 > 131072). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 5622/5622 [00:24<00:00, 228.00it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "all_len = []\n",
    "all_result = []\n",
    "\n",
    "for input_data_ in tqdm(input_data):\n",
    "    text = input_data_[\"text\"]\n",
    "    count = len(tokenizer(text)[\"input_ids\"])\n",
    "    if count <= 2048:\n",
    "        # data[\"text\"] = data[\"text\"]\n",
    "        all_result.append(input_data_)\n",
    "    all_len.append(count)\n",
    "\n",
    "with open(\"../data/qwen_multi_news_test_data.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(all_result, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': '<|im_start|>system\\n<|mrc|>False\\n<|summary|>True<|im_end|>\\n<|im_start|>user\\n**Document**\\n[1] National Archives\\n[2] Yes, it’s that time again, folks. It’s the first Friday of the month, when for one ever-so-brief moment the interests of Wall Street, Washington and Main Street are all aligned on one thing: Jobs.\\n[3] A fresh update on the U.S. employment situation for January hits the wires at 8:30 a.m. New York time offering one of the most important snapshots on how the economy fared during the previous month. Expectations are for 203,000 new jobs to be created, according to economists polled by Dow Jones Newswires, compared to 227,000 jobs added in February. The unemployment rate is expected to hold steady at 8.3%.\\n[4] Here at MarketBeat HQ, we’ll be offering color commentary before and after the data crosses the wires. Feel free to weigh-in yourself, via the comments section. And while you’re here, why don’t you sign up to follow us on Twitter.\\n[5] Enjoy the show.\\n[6] Employers pulled back sharply on hiring last month, a reminder that the U.S. economy may not be growing fast enough to sustain robust job growth. The unemployment rate dipped, but mostly because more Americans stopped looking for work.\\n[7] The Labor Department says the economy added 120,000 jobs in March, down from more than 200,000 in each of the previous three months.\\n[8] The unemployment rate fell to 8.2 percent, the lowest since January 2009. The rate dropped because fewer people searched for jobs. The official unemployment tally only includes those seeking work.\\n[9] The economy has added 858,000 jobs since December _ the best four months of hiring in two years. But Federal Reserve Chairman Ben Bernanke has cautioned that the current hiring pace is unlikely to continue without more consumer spending.\\n<|im_end|>\\n<|im_start|>assistant\\n**Answer**\\n**Summary**\\nThe unemployment rate dropped to 8.2% last month, but the economy only added 120,000 jobs, when 203,000 new jobs had been predicted, according to today\\'s jobs report. Reaction on the Wall Street Journal\\'s MarketBeat Blog was swift: \"Woah!!! Bad number.\" The unemployment rate, however, is better news; it had been expected to hold steady at 8.3%. But the AP notes that the dip is mostly due to more Americans giving up on seeking employment.\\n<|im_end|>\\n'}\n"
     ]
    }
   ],
   "source": [
    "print(all_result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2270/5622 [00:11<00:17, 193.28it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (176797 > 131072). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 5622/5622 [00:28<00:00, 198.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_len = []\n",
    "all_result = []\n",
    "over_num = 0\n",
    "for input_data_ in tqdm(input_data):\n",
    "    text = input_data_[\"all_text\"]\n",
    "    count = len(tokenizer(text)[\"input_ids\"])\n",
    "    if count <= 2048:\n",
    "        all_result.append(input_data_)\n",
    "    else:\n",
    "        over_len = count - 2048\n",
    "        input_data_['text'] = input_data_['text'][:over_len]\n",
    "        over_num +=1\n",
    "    # all_len.append(len(tokenizer(text)[\"input_ids\"]))\n",
    "print(over_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/qwen_cnn_test_data.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/qwen_cnn_test_data.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      2\u001b[0m     json\u001b[38;5;241m.\u001b[39mdump(all_result, f, ensure_ascii\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n",
      "File \u001b[0;32m~/workspace/XAI_rationale-inference-LLM/.venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[0;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/qwen_cnn_test_data.json'"
     ]
    }
   ],
   "source": [
    "with open(\"data/qwen_cnn_test_data.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(all_result, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in all_result:\n",
    "    result[\"label\"] = \"assistant\\n\" + result[\"label\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/qwen_dev_data.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(all_result, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7405it [00:17, 426.88it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "all_len = []\n",
    "all_result = []\n",
    "\n",
    "for data, input_data_ in tqdm(zip(dev_data, input_data)):\n",
    "    text = input_data_[\"text\"]\n",
    "    if len(tokenizer(text)[\"input_ids\"]) <= 2048:\n",
    "        # data[\"text\"] = data[\"text\"]\n",
    "        all_result.append(data)\n",
    "    # all_len.append(len(tokenizer(text)[\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/teddst_dev.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(input_data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Answer**: yes\n",
      "**Supporting Sentences**: [4] Scott Derrickson (born July 16, 1966) is an American director, screenwriter and producer.\n",
      "[17] Edward Davis Wood Jr. (October 10, 1924 – December 10, 1978) was an American filmmaker, actor, writer, producer, and director.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(input_data[0][\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6539\n"
     ]
    }
   ],
   "source": [
    "count = len(list(filter(lambda x: x < 2048, all_len)))\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
