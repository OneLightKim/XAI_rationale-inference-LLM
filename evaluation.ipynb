{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def normalize_answer(s):\n",
    "    \"\"\"간단한 토큰화와 정규화\"\"\"\n",
    "    s = s.lower()  # 소문자 변환\n",
    "    s = re.sub(r'\\b(a|an|the)\\b', ' ', s)  # 불필요한 관사 제거\n",
    "    s = re.sub(r'[^a-z0-9]', ' ', s)  # 알파벳과 숫자 외 제거\n",
    "    return ' '.join(s.split())  # 공백 정리\n",
    "\n",
    "def exact_match_score(prediction, ground_truth):\n",
    "    \"\"\"예측 답과 실제 답 간의 EM 점수 계산\"\"\"\n",
    "    return int(normalize_answer(prediction) == normalize_answer(ground_truth))\n",
    "\n",
    "def f1_score_hotpot(prediction, ground_truth):\n",
    "    \"\"\"예측 답과 실제 답 간의 F1 점수 계산\"\"\"\n",
    "    pred_tokens = normalize_answer(prediction).split()\n",
    "    gt_tokens = normalize_answer(ground_truth).split()\n",
    "    \n",
    "    common_tokens = set(pred_tokens) & set(gt_tokens)\n",
    "    num_common = len(common_tokens)\n",
    "    \n",
    "    if num_common == 0:\n",
    "        return 0\n",
    "    \n",
    "    precision = num_common / len(pred_tokens)\n",
    "    recall = num_common / len(gt_tokens)\n",
    "    \n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"result/1105/hotpot_tt_2000.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    dev_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n",
      "yes\n",
      "----\n",
      "Chief of Protocol\n",
      "Sericety of State for Constitutional Affairs\n",
      "----\n",
      "Animorphs\n",
      "Animrophs\n",
      "----\n",
      "no\n",
      "yes\n",
      "----\n",
      "Greenwich Village, New York City\n",
      "New York City\n",
      "----\n",
      "YG Entertainment\n",
      "YG Entertainment\n",
      "----\n",
      "Eenasul Fateh\n",
      "Eenasul Gameth\n",
      "----\n",
      "3,677 seated\n",
      "4,000\n",
      "----\n",
      "Terry Richardson\n",
      "Anside Morton\n",
      "----\n",
      "yes\n",
      "yes\n",
      "----\n",
      "Kansas Song\n",
      "Kansas Song\n",
      "----\n",
      "David Weissman\n",
      "David Dewissman\n",
      "----\n",
      "1999\n",
      "1999\n",
      "----\n",
      "no\n",
      "yes\n",
      "----\n",
      "from 1986 to 2013\n",
      "1945 to 1969\n",
      "----\n",
      "9,984\n",
      "9,984\n",
      "----\n",
      "the North Atlantic Conference\n",
      "Eastern Councilamic Association-North\n",
      "----\n",
      "yes\n",
      "yes\n",
      "----\n",
      "1969 until 1974\n",
      "1969 to 1974\n",
      "----\n",
      "Robert Erskine Childers DSC\n",
      "Robert Arksine Childers\n",
      "----\n",
      "Pedro Rodríguez\n",
      "Eudardo Troconis\n",
      "----\n",
      "Sonic\n",
      "The:Herdegos\n",
      "----\n",
      "keyboard function keys\n",
      "Mth Group\n",
      "----\n",
      "Badly Drawn Boy\n",
      "Wolf Alice\n",
      "----\n",
      "World's Best Goalkeeper\n",
      "Gus Williams\n",
      "----\n",
      "Barton Lee Hazlewood\n",
      "LeestHazlewood\n",
      "----\n",
      "1838\n",
      "1838\n",
      "----\n",
      "yes\n",
      "yes\n",
      "----\n",
      "Henry J. Kaiser\n",
      "Henry J. Kaiser\n",
      "----\n",
      "Arena of Khazan\n",
      "Carusaders of Khazan\n",
      "----\n",
      "2000\n",
      "2000\n",
      "----\n",
      "Fujioka, Gunma\n",
      "Finla n\n",
      "----\n",
      "Charles Eugène\n",
      "Charles Nungserter\n",
      "----\n",
      "no\n",
      "yes\n",
      "----\n",
      "Letters to Cleo\n",
      "More members in Sreesamlry Trees\n",
      "----\n",
      "October 1922\n",
      "1923\n",
      "----\n",
      "2000\n",
      "2000\n",
      "----\n",
      "World War II\n",
      "World War II\n",
      "----\n",
      "no\n",
      "yes\n",
      "----\n",
      "New York City\n",
      "New York City\n",
      "----\n",
      "Scotch Collie\n",
      "Scottch Collie\n",
      "----\n",
      "Mumbai\n",
      "M Mumbai, Maharashtra\n",
      "----\n",
      "1962\n",
      "1962\n",
      "----\n",
      "sovereignty\n",
      "Soliovery\n",
      "----\n",
      "Nelson Rockefeller\n",
      "Gerson Johndoemoe\n",
      "----\n",
      "Yellowcraig\n",
      "Firth of Forth\n",
      "----\n",
      "Phil Spector\n",
      "Phil Spector\n",
      "----\n",
      "Organizations could come together to address global issues\n",
      "public and physical action\n",
      "----\n",
      "yes\n",
      "yes\n",
      "----\n",
      "English Electric Canberra\n",
      "English Committee Canberra\n",
      "----\n",
      "2009 Big 12 Conference\n",
      "2009\n",
      "----\n",
      "1,462\n",
      "1,462\n",
      "----\n",
      "Indianapolis Motor Speedway\n",
      "Indiasispanol Movement Screenford City River City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City City\n",
      "----\n",
      "Rome\n",
      "New York City\n",
      "----\n",
      "Max Martin, Savan Kotecha and Ilya Salmanzadeh\n",
      "Max Martin\n",
      "----\n",
      "Marion, South Australia\n",
      "Marion\n",
      "----\n",
      "Drifting\n",
      "drifting\n",
      "----\n",
      "Keith Bostic\n",
      "Keith Bostic\n",
      "----\n",
      "35,124\n",
      "4,505\n",
      "----\n",
      "no\n",
      "yes\n",
      "----\n",
      "shortest player ever to play in the National Basketball Association\n",
      "CEO of the San Antonio Super Dogs\n",
      "----\n",
      "Ronald Shusett\n",
      "Gordon Carroll\n",
      "----\n",
      "Adeline Virginia Woolf\n",
      "Emma Bull\n",
      "----\n",
      "821\n",
      "821\n",
      "----\n",
      "more than 70 countries\n",
      "70\n",
      "----\n",
      "Charmed\n",
      "Charmed\n",
      "----\n",
      "International Boxing Hall of Fame\n",
      "International Boxing Hall of Fame\n",
      "----\n",
      "Usher\n",
      "U Sher\n",
      "----\n",
      "Bill Murray\n",
      "Bandesary Cearz\n",
      "----\n",
      "Carabao Cup\n",
      "Carabato Cup\n",
      "----\n",
      "Teen Titans Go!\n",
      "Teen Titans\n",
      "----\n",
      "276,170 inhabitants\n",
      "India\n",
      "----\n",
      "orange\n",
      "once older, then a big shirts, caps andscaraf\n",
      "----\n",
      "Tromeo and Juliet\n",
      "Troma Entertainment\n",
      "----\n",
      "William Jefferson Clinton\n",
      "William Jefferson Clinton\n",
      "----\n",
      "John John Florence\n",
      "John John Florence\n",
      "----\n",
      "Ann\n",
      "Christopher\n",
      "----\n",
      "Apalachees\n",
      "Ais\n",
      "----\n",
      "British\n",
      "Indian\n",
      "----\n",
      "1865\n",
      "1910\n",
      "----\n",
      "Newport\n",
      "New Newport\n",
      "----\n",
      "Bob Seger\n",
      "Rob Roberts\n",
      "----\n",
      "Conscription\n",
      "the fight of one name\n",
      "----\n",
      "Mondelez International, Inc.\n",
      "Montdelez International, Indiana\n",
      "----\n",
      "Monica Lewinsky\n",
      "Mimi Alford\n",
      "----\n",
      "April 1, 1949\n",
      "1949\n",
      "----\n",
      "1866\n",
      "1866\n",
      "----\n",
      "Canary Islands, Spain\n",
      "In the central and north of La Gomura\n",
      "----\n",
      "250 million\n",
      "250 million\n",
      "----\n",
      "director\n",
      "director\n",
      "----\n",
      "The Conversation\n",
      "The Competition Community Network\n",
      "----\n",
      "John Waters\n",
      "John Saleswery\n",
      "----\n",
      "Las Vegas Strip in Paradise\n",
      "Las Vegas Strip\n",
      "----\n",
      "no\n",
      "yes\n",
      "----\n",
      "March and April\n",
      "March\n",
      "----\n",
      "Fairfax County\n",
      "Fairface County\n",
      "----\n",
      "IT products and services\n",
      "it offers physical devices and services to hospital services and companies in the health series .\n",
      "----\n",
      "Levni Yilmaz\n",
      "Paulamela B. Gordon\n",
      "----\n",
      "Beijing\n",
      "Chicago\n",
      "----\n",
      "no\n",
      "yes\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "result_f1 = []\n",
    "result_em = []\n",
    "for dev in dev_data:\n",
    "    predict = \"\"\n",
    "    answer = dev[\"answer\"].split(\"**Summary:\")[0].replace(\"**Answer:\", \"\").replace(\"<|im_start|>assistant\", \"\")\n",
    "    generated_text = dev[\"generated_text\"].split(\"**Summary:\")[0].replace(\"**Answer:\", \"\")\n",
    "    if answer == \"yes\":\n",
    "        if answer in generated_text.lower() and \"no\" not in generated_text.lower():\n",
    "            generated_text = \"yes\"\n",
    "        else:\n",
    "            generated_text = \"\"\n",
    "    elif answer == \"no\":\n",
    "        if answer in generated_text.lower() and \"yes\" not in generated_text.lower():\n",
    "            generated_text = \"no\"\n",
    "        else:\n",
    "            generated_text = \"\"\n",
    "    answer = answer.strip()\n",
    "    predict = generated_text.strip()\n",
    "    print(answer)\n",
    "    print(predict)\n",
    "    print(\"----\")\n",
    "    result_f1.append(f1_score_hotpot(answer, predict))\n",
    "    result_em.append(exact_match_score(predict, answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 점수:  0.413095238095238\n",
      "EM 점수:  0.28\n"
     ]
    }
   ],
   "source": [
    "# F1 점수와 EM 점수 출력\n",
    "print(\"F1 점수: \", sum(result_f1) / len(result_f1))\n",
    "print(\"EM 점수: \", sum(result_em) / len(result_em))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'qwen_answer_cnn_50.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mqwen_answer_cnn_50.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m      3\u001b[0m     dev_data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(file)\n",
      "File \u001b[0;32m~/workspace/XAI_rationale-inference-LLM/.venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[0;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'qwen_answer_cnn_50.json'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(\"qwen_answer_cnn_50.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    dev_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "def calculate_rouge(predicted_summary, reference_summary):\n",
    "    # ROUGE 계산기 생성 (rouge1, rouge2, rougeL을 사용)\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    \n",
    "    # ROUGE 점수 계산\n",
    "    scores = scorer.score(reference_summary, predicted_summary)\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Membership gives the ICC jurisdiction over alleged crimes committed in Palestinian territories since last June . Israel and the United States opposed the move, which could open the door to war crimes investigations against Israelis .\n",
      "Palestinians joined the International Criminal Court on Wednesday, becoming the 123rd member. The move gives the court jurisdiction over alleged crimes in Palestinian territories.\n",
      "----\n",
      "Theia, a bully breed mix, was apparently hit by a car, whacked with a hammer and buried in a field . \"She's a true miracle dog and she deserves a good life,\" says Sara Mellado, who is looking for a home for Theia .\n",
      "Theia, a dog who was hit by a car, beaten with a hammer and buried. Theia survived. A dog who was hit by a car, beaten with a hammer and buried, has survived. She's now at a veterinary teaching hospital.\n",
      "----\n",
      "Mohammad Javad Zarif has spent more time with John Kerry than any other foreign minister . He once participated in a takeover of the Iranian Consulate in San Francisco . The Iranian foreign minister tweets in English .\n",
      "Mohammad Javad Zarif is the Iranian foreign minister. He was nominated to be foreign minister by Hassan Rouhami. He received a hero's welcome as he arrived in Iran on a sunny Friday morning.\n",
      "----\n",
      "17 Americans were exposed to the Ebola virus while in Sierra Leone in March . Another person was diagnosed with the disease and taken to hospital in Maryland . National Institutes of Health says the patient is in fair condition after weeks of treatment .\n",
      "CDC says last of 17 patients will be released by Thursday. Five Americans who were monitored at a Nebraska hospital have been released.\n",
      "----\n",
      "Student is no longer on Duke University campus and will face disciplinary review . School officials identified student during investigation and the person admitted to hanging the noose, Duke says . The noose, made of rope, was discovered on campus about 2 a.m.\n",
      "Duke University student admitted to hanging noose. No other people were involved, but criminal investigations are ongoing. Duke University students march after discovery.\n",
      "----\n",
      "College-bound basketball star asks girl with Down syndrome to high school prom . Pictures of the two during the \"prom-posal\" have gone viral .\n",
      "Trey Moses, a star basketball player at Eastern High School in Louisville, Kentucky, asked Ellie Meredith, a 15-year-old with Down syndrome, to prom. The pair met through a special program at their school that pairs students with special needs with others who don't. Trey's mother Shelly Moses says the pair have a lot in common: \"They both love Taylor Swift and they both love to play basketball.\"\n",
      "----\n",
      "Amnesty's annual death penalty report catalogs encouraging signs, but setbacks in numbers of those sentenced to death . Organization claims that governments around the world are using the threat of terrorism to advance executions . The number of executions worldwide has gone down by almost 22% compared with 2013, but death sentences up by 28% .\n",
      "Amnesty International's annual report on the death penalty shows that the number of executions worldwide has gone down by almost 22% on the previous year. At least 607 people were executed around the world in 2014, compared to 778 in 2013. The report cites the example of Pakistan lifting a six-year moratorium on the execution of civilians following the horrific attack on a school in Peshawar in December. The report notes that the spike in sentencing is attributable to mass-sentencing in countries including Egypt and Nigeria, \"against scores of people in some cases.\" Opinion: Sharp spike in death sentences.\n",
      "----\n",
      "Andrew Getty's death appears to be from natural causes, police say, citing coroner's early assessment . In a petition for a restraining order, Getty had written he had a serious medical condition. Police say this is not a criminal matter at this time .\n",
      "Andrew Getty, 47, appears to have died of natural causes, a Los Angeles Police Department spokesman said. He had several health issues, an autopsy will be conducted.\n",
      "----\n",
      "Once a super typhoon, Maysak is now a tropical storm with 70 mph winds . It could still cause flooding, landslides and other problems in the Philippines .\n",
      "The storm is classified as a tropical storm, but could still cause flooding and landslides. It's forecast to make landfall Sunday morning on the southeastern coast of Isabela province.\n",
      "----\n",
      "Bob Barker returned to host \"The Price Is Right\" on Wednesday . Barker, 91, had retired as host in 2007 .\n",
      "Bob Barker, 91, hosted his first \"Price is Right\" show since 2007. He will host the show's finale May 29.\n",
      "----\n",
      "London's Metropolitan Police say the man was arrested at Luton airport after landing on a flight from Istanbul . He's been charged with terror offenses allegedly committed since the start of November .\n",
      "The 19-year-old has been charged with terror offenses after being arrested at Luton Airport. The teenager, who is a UK national, had traveled from Istanbul on a flight.\n",
      "----\n",
      "\"Furious 7\" pays tribute to star Paul Walker, who died during filming . Vin Diesel: \"This movie is more than a movie\" \"Furious 7\" opens Friday .\n",
      "Paul Walker died in a car crash in 2013. He was the star of the \"Fast & Furious\" franchise. His brother Cody says he would be proud of \"Furious 7\".\n",
      "----\n",
      "Museum: Anne Frank died earlier than previously believed . Researchers re-examined archives and testimonies of survivors . Anne and older sister Margot Frank are believed to have died in February 1945 .\n",
      "New research suggests Anne Frank died a month earlier than previously thought. New study re-examined archives of the Red Cross, the International Training Service and the Bergen-Belsen Memorial. Researchers concluded that Anne and her older sister, Margot Frank, died at least a month earlier than previously thought.\n",
      "----\n",
      "LZ: Indiana law pushing back LGBT rights, and other states' anti-LGBT moves, bow to far right wing that GOP candidates need for 2016 . Cruz, Huckabee, Jindal, Carson, Walker are reviving culture wars, he says.  Equality for LGBT has not yet \"won\" in America .\n",
      "Mike Pence, a favorite of the Koch brothers, signed a religious freedom bill that allows discrimination against gays and lesbians. The move drew criticism from the GOP and the Democratic Party. Republicans are now trying to figure out how to handle the backlash. The move may help them in the primaries but could hurt them in the general election.\n",
      "----\n",
      "Singing the national anthem is a risky proposition . Whitney Houston nailed it; Roseanne Barr destroyed it .\n",
      "Vince Neil: \"The Star-Spangled Banner\" singer mangled the national anthem at a Las Vegas football game. He was booed by the crowd. Jimi Hendrix: Guitarist's psychedelic version of the anthem inflamed mainstream America. Whitney Houston: Singer's rendition at Super Bowl XXV set the modern standard. Roseanne Barr: Comedian's rendition of the anthem at a San Diego Padres game was booed. Michael Bolton: Singer's rendition of the anthem at an American League Championship Series game was overwrought.\n",
      "----\n",
      "While Republican Gov. Asa Hutchinson was weighing an Arkansas religious freedom bill, Walmart voiced its opposition . Walmart and other high-profile businesses are showing their support for gay and lesbian rights . Their stance puts them in conflict with socially conservative Republicans, traditionally seen as allies .\n",
      "Walmart's opposition to a religious freedom law in Arkansas is part of a broader trend. The company's opposition to the measure comes as it boosts wages and expands health benefits.\n",
      "----\n",
      "Amnesty International releases its annual review of the death penalty worldwide; much of it makes for grim reading . Salil Shetty: Countries that use executions to deal with problems are on the wrong side of history .\n",
      "The death penalty was used to tackle crime and terrorism in 2014, according to a new report. Amnesty International says many of those executed were drug traffickers. In Pakistan, the government lifted a six-year moratorium on the death penalty. In Iran, the government said it was a move to end a surge in violent crime. The death penalty was used to tackle crime and terrorism in 2014, according to a new report. Amnesty International says many of those executed were drug traffickers. In Pakistan, the government lifted a six-year moratorium on the death penalty. In Iran, the government said it was a move to end a surge in violent crime. The death penalty was used to tackle crime and terrorism in 2014, according to a new report. Amnesty International says many of those executed were drug traffickers. In Pakistan, the government lifted a six-year moratorium on the death penalty. In Iran, the government said it was a move to end a surge in violent crime. The death penalty was used to tackle crime and terrorism in 2014, according to a new report. Amnesty International says many of those executed were drug traffickers. In Pakistan, the government\n",
      "----\n",
      "Marseille prosecutor says \"so far no videos were used in the crash investigation\" despite media reports . Journalists at Bild and Paris Match are \"very confident\" the video clip is real, an editor says . Andreas Lubitz had informed his Lufthansa training school of an episode of severe depression, airline says .\n",
      "French prosecutor says no video footage was recovered from Germanwings Flight 9525 crash site. Paris Match and Bild claim they watched cell phone video showing final moments of plane. No cell phones have been sent to criminal research institute for analysis. Two sources say Lubitz was in good health when he flew Germanwings Flight 9525.\n",
      "----\n",
      "The Rev. Robert Schuller, 88, had been diagnosed with esophageal cancer in 2013 . His TV show, \"Hour of Power,\" was enormously popular in the 1970s and 1980s .\n",
      "Robert H. Schuller, 88, televangelist and founder of \"Hour of Power\" died Thursday. Schuller was born in an Iowa farmhouse without running water. He and his wife met while she played the organ at his church.\n",
      "----\n",
      "Former GOP representative compares President Obama to Andreas Lubitz . Bachmann said with possible Iran deal, Obama will fly \"entire nation into the rocks\" Reaction on social media? She was blasted by Facebook commenters .\n",
      "Bachmann compares Obama to Andreas Lubitz, the co-pilot of Germanwings Flight 9525. The congresswoman says Obama is \"for the 300 million souls of the United States\" what Lubitz was for 150 souls.\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "rouge1 = []\n",
    "rouge2 = []\n",
    "rougeL = []\n",
    "for dev in dev_data:\n",
    "    predict = \"\"\n",
    "    answer = dev[\"answer\"].split(\"**Summary**\")[1].strip()\n",
    "    generated_text = dev[\"generated_text\"].split(\"assistant\\n\")[1]\n",
    "    if \"**Answer**\" in generated_text:\n",
    "        predict = generated_text.split(\"**Answer**\")[1].replace(\"**Summary**\\n\", \"\")\n",
    "    else:\n",
    "        predict = generated_text\n",
    "    \n",
    "    answer = answer.strip()\n",
    "    predict = predict.strip()\n",
    "    print(answer)\n",
    "    print(predict)\n",
    "    print(\"----\")\n",
    "    rouge_scores = calculate_rouge(predict, answer)\n",
    "    rouge1.append(rouge_scores['rouge1'].fmeasure)\n",
    "    rouge2.append(rouge_scores['rouge2'].fmeasure)\n",
    "    rougeL.append(rouge_scores['rougeL'].fmeasure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33227131701560736\n",
      "0.13398218246023427\n",
      "0.2444843813224157\n"
     ]
    }
   ],
   "source": [
    "print(sum(rouge1)/len(rouge1))\n",
    "print(sum(rouge2)/len(rouge2))\n",
    "print(sum(rougeL)/len(rougeL))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 근거 문장 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"result/qwen_lora_1101/hotpot_tt_9000.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    test_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"data/1029data/hotpot_dev_supporting.json\"\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    dev_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_supporting_facts(gold_sp, pred_sp):\n",
    "    \"\"\"Supporting facts에 대한 EM, Precision, Recall, F1 점수를 계산하는 함수\"\"\"\n",
    "    # 단일 정수를 리스트로 변환\n",
    "    gold_sp = [gold_sp] if isinstance(gold_sp, int) else gold_sp\n",
    "    pred_sp = [pred_sp] if isinstance(pred_sp, int) else pred_sp\n",
    "    \n",
    "    # 예측과 정답 집합으로 변환\n",
    "    gold_set = set(gold_sp)\n",
    "    pred_set = set(pred_sp)\n",
    "    \n",
    "    # True Positives 계산\n",
    "    tp = len(gold_set & pred_set)\n",
    "    \n",
    "    # Precision, Recall 계산\n",
    "    precision = tp / len(pred_set) if pred_set else 0\n",
    "    recall = tp / len(gold_set) if gold_set else 0\n",
    "    \n",
    "    # F1 점수 계산\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    # Exact Match 계산\n",
    "    em = 1 if gold_set == pred_set else 0\n",
    "    \n",
    "    return em, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from 1986 to 2013\n",
      "1945 to 1969\n",
      "It is named in honour of Sir Matt Busby, the football manager who was born in Bellshill in 1909, managed Manchester United from 1945 to 1969 and died in 1994.\n",
      "================\n",
      "Badly Drawn Boy\n",
      "Badly Drawn Boy\n",
      "About a Boy is a 2002 British-American-French comedy-drama film produced by Jane Rosenthal, Robert De Niro, Brad Epstein, Tim Bevan and Eric Fellner, co-written and directed by brothers Chris Weitz and Paul Weitz with music by Badly Drawn Boy and written by Peter Hedges.\n",
      "================\n",
      "Henry J. Kaiser\n",
      "Henry J. Kaiser\n",
      "The shipyards were owned by the Kaiser Shipbuilding Company, a creation of American industrialist Henry J. Kaiser, (1882-1967), who established the shipbuilding company around 1939 in order to help meet the construction goals set by the United States Maritime Commission for merchant shipping.\n",
      "================\n",
      "Letters to Cleo\n",
      "Screaming Trees\n",
      "Conner began his career with Screaming Trees in 1985 which lasted until their disbanding in 2000.\n",
      "================\n",
      "sovereignty\n",
      "its sovereignty\n",
      "Ethiopia's borders underwent significant territorial expansion to its modern borders for the rest of the century, especially by Emperor Menelik II and Ras Gobena, culminating in its victory over the Italians at the Battle of Adwa in 1896 with the military leadership of Ras Makonnen, and ensuring its sovereignty and freedom from colonization.\n",
      "================\n",
      "Adeline Virginia Woolf\n",
      "Virginia Woolf\n",
      "The collection was first found in the papers of her husband, used by Quentin Bell in his biography of Virginia Woolf, published in 1972.\n",
      "================\n",
      "The Conversation\n",
      "The Conversation\n",
      "\"The Conversation\" publishes all content under a Creative Commons license and, as of May 2017, reports a monthly online audience of 5.2 million users onsite, and a reach of 35 million people through creative commons republication.\n",
      "================\n",
      "Fairfax County\n",
      "Fairfax County\n",
      "It is a popular destination for recreation and hiking and is operated by the Fairfax County Park Authority.\n",
      "================\n"
     ]
    }
   ],
   "source": [
    "score = []\n",
    "all_em_score = []\n",
    "all_precision_score = []\n",
    "all_recall_score = []\n",
    "all_f1_score = []\n",
    "ignore = 0\n",
    "for dev, data in zip(dev_data, test_data):\n",
    "    assert dev[\"_id\"] == data[\"_id\"]\n",
    "    predict = \"\"\n",
    "    answer = data[\"answer\"].split(\"**Summary:\")[0].replace(\"**Answer:\", \"\").replace(\"<|im_start|>assistant\", \"\").strip()\n",
    "    generated_text = data[\"generated_text\"].split(\"**Summary:\")[0].replace(\"**Answer:\", \"\").strip()\n",
    "    if answer == \"yes\":\n",
    "        if answer in generated_text.lower() and \"no\" not in generated_text.lower():\n",
    "            generated_text = \"yes\"\n",
    "        else:\n",
    "            generated_text = \"\"\n",
    "    elif answer == \"no\":\n",
    "        if answer in generated_text.lower() and \"yes\" not in generated_text.lower():\n",
    "            generated_text = \"no\"\n",
    "        else:\n",
    "            generated_text = \"\"\n",
    "    answer = answer.strip()\n",
    "    predict = generated_text.strip()\n",
    "    result_f1.append(f1_score_hotpot(answer, predict))\n",
    "    result_em.append(exact_match_score(predict, answer))\n",
    "    ################################################\n",
    "    gold_sp = data[\"gold_sp\"]\n",
    "    pred_sp = data[\"pred_sp\"]\n",
    "    em, precision, recall, f1 = evaluate_supporting_facts(gold_sp, pred_sp)\n",
    "    all_em_score.append(em)\n",
    "    all_precision_score.append(precision)\n",
    "    all_recall_score.append(recall)\n",
    "    all_f1_score.append(f1)\n",
    "    \n",
    "    for i in pred_sp:\n",
    "        if answer == \"yes\" or answer == \"no\":\n",
    "            ignore += 1\n",
    "            break\n",
    "        if predict in dev[\"sent\"][i-1]:\n",
    "            score.append(dev[\"_id\"])\n",
    "            print(answer)\n",
    "            print(generated_text)\n",
    "            print(dev[\"sent\"][i-1])\n",
    "            print(\"================\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 점수:  0.5790318919532406\n",
      "EM 점수:  0.4519350811485643\n"
     ]
    }
   ],
   "source": [
    "# F1 점수와 EM 점수 출력\n",
    "print(\"F1 점수: \", sum(result_f1) / len(result_f1))\n",
    "print(\"EM 점수: \", sum(result_em) / len(result_em))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_f1_score 점수:  0.0\n",
      "all_em_score 점수:  0.0\n",
      "all_precision_score 점수:  0.0\n",
      "all_recall_score 점수:  0.0\n"
     ]
    }
   ],
   "source": [
    "# F1 점수와 EM 점수 출력\n",
    "print(\"all_f1_score 점수: \", sum(all_f1_score) / len(all_f1_score))\n",
    "print(\"all_em_score 점수: \", sum(all_em_score) / len(all_em_score))\n",
    "print(\"all_precision_score 점수: \", sum(all_precision_score) / len(all_precision_score))\n",
    "print(\"all_recall_score 점수: \", sum(all_recall_score) / len(all_recall_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
